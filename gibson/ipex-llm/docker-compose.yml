services:
  ipex-llm-inference:
    image: intelanalytics/ipex-llm-inference-cpp-xpu:latest
    container_name: ipex-llm
    devices:
      - /dev/dri
    volumes:
      - /nfs/cistern/docker/data/ipex/models:/models
    environment:
      - no_proxy=localhost,127.0.0.1
      - DEVICE=Arc
    shm_size: "16g"
    mem_limit: "32g"
    restart: unless-stopped

networks:
  default:
    external:
      name: vtluug-network